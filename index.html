<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
		
<title>Accelerating Big Data Processing</title> 


<center> <h2>Resource and Job Management in HPC clusters with Slurm: Administration, Usage and Performance Evaluation<br> </h2> <h3> A
Tutorial to be presented at <a href="http://www.ieeecluster2016.org/">IEEE Cluster 2016</a><br>by<br> Yiannis Georgiou and David Glesser Bull - Atos Technologies </h3> </center>

		<hr>

<br> <h3>Abstract</h3>

High Performance Computing is characterized by the continuous evolution of computing architectures, the proliferation of computing resources and the increasing complexity of applications, users wish to execute. One of the most important software of the HPC software stack that deals with both hardware resources evolutions and applications' needs is the Resource and Job Management System (RJMS). This systems software which stands between the user workloads and the infrastructure, provides functions to configure and manage the pool of resources along with features for building, submitting, scheduling and monitoring user jobs in a dynamic computing environment.

This tutorial is upon <a href="http://slurm.schedmd.com">Slurm</a> Resource and Job Management System. Slurm is an open source RJMS, specifically designed for the scalability requirements of state-of-the-art HPC clusters. As of the November 2015 Top500 supercomputer list, Slurm is being used on five of the ten most powerful computers in the world including the no1 system, Tianhe-2 with 3,120,000 computing cores. Throughout the years, it has evolved from a simple resource management software to a complex but very powerful resource and job manager, workload scheduler and an interesting research tool.

The tutorial will give an overview of the concepts and underlying architecture of Slurm and it will focus on both administrator configuration and user executions related aspects.


<br>

		<h3>Outline of the Tutorial</h3>

The tutorial will be decomposed into three parts: Administration, Usage and Performance Evaluation.

On the administration part there will be a detailed description and hands-on for features such as job prioritization, resources selection, GPGPUs and generic resources, advanced reservations, accounting (associations, QOS, etc), scheduling(backfill, preemption), high availability, power management, topology aware placement, licenses management, burst buffers, scalability tuning with a particular focus on the configuration of the newly developed power adaptive scheduling technique.

The usage training part will provide in-depth analysis and hands-on for CPU usage parameters, options for multi-core and multi-threaded architectures, prolog and epilog scripts, job arrays, MPI tight integration, CPU frequency scaling usage, accounting / reporting and profiling of user jobs. Finally there will be a particular focus on some new functionalities within Slurm such as the usage of power adaptive scheduling (appeared in version 15.08) and the support of heterogeneous resources job specification language along with the multiple program multiple data (MPMD) MPI support (to appear in version 17.02).

Finally the performance evaluation part will consist of techniques with hands-on to experiment with Slurm in large scales using simulation and emulation which will be valuable for researchers and developers. For the hands-on exercises particular VM and/or container environments will be made available along with a pre-installed testbed cluster to enable the experimentation of the different functionalities.		
<br>
		<hr>

		<address>Last Updated: June 17, 2016</address>

</body></html>

